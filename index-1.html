<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Astropeak (old posts, page 1)</title>
<style>
        @font-face {
            font-family: "libretto-icons";
            src:url(assets/fonts/libretto-icons.eot);
            src:url(assets/fonts/libretto-icons.eot#iefix) format("embedded-opentype"),
            url(assets/fonts/libretto-icons.woff) format("woff"),
            url(assets/fonts/libretto-icons.ttf) format("truetype"),
            url(assets/fonts/libretto-icons.svg#libretto-icons) format("svg");
            font-weight: normal;
            font-style: normal;
        }
    </style>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Sans+Mono%7CLibre+Baskerville%7CMontserrat%7CPlayfair+Display">
<link rel="stylesheet" href="assets/css/libretto_styles.css">
<link href="assets/css/custom.css" rel="stylesheet" type="text/css">
</head>
<body>
    <!-- Navigation bar -->
    <header class="nav-bar"><div class="site-branding">
            <h1 class="site-title">
                <a href="https://astropeak.github.io/" title="Astropeak" rel="home">Astropeak</a>
            </h1>
        </div>
        <nav class="site-navigation" role="navigation"><div class="menu-toggle">
                <span class="mobile-site-title">Astropeak</span>
            </div>
            <ul class="menu">
<li><a href="archive.html">Archive</a></li>
                    <li><a href="categories/">Tags</a></li>
                    <li><a href="rss.xml">RSS feed</a></li>
                    <li><a href="http://github.com/astropeak">Github</a></li>
            </ul></nav></header><div class="site-content">
            <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
                    <div class="entry-meta">
                        <span class="posted-on">
                            Posted on <a href="posts/nlp-vocabulary/" rel="bookmark">March 13, 2017</a>
                        </span>
                    </div>
                    <h1><a href="posts/nlp-vocabulary/">自然语言处理名词表</a></h1>
                </div>
                <div class="entry-content">
                        <table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="left">
<col class="left">
<col class="left">
</colgroup>
<thead><tr>
<th scope="col" class="left">名词</th>
<th scope="col" class="left">英文</th>
<th scope="col" class="left">含义</th>
</tr></thead>
<tbody><tr>
<td class="left">词性标注</td>
<td class="left">part of speech, tagging, POS</td>
<td class="left">给定一个句子，为每个词标注词性</td>
</tr></tbody>
<tbody><tr>
<td class="left"> </td>
<td class="left">N－gram</td>
<td class="left">一种文档表示模型，详见 <a href="posts/nlp-vocabulary/bag-of-word-and-ngram-model.html">这里</a>
</td>
</tr></tbody>
<tbody><tr>
<td class="left">词袋</td>
<td class="left">bag of words</td>
<td class="left">一种文档表示模型</td>
</tr></tbody>
<tbody><tr>
<td class="left">停止词</td>
<td class="left">stop word</td>
<td class="left">常用词，如 the， a， of</td>
</tr></tbody>
<tbody><tr>
<td class="left">词根</td>
<td class="left">steming</td>
<td class="left">一个词的词根</td>
</tr></tbody>
<tbody><tr>
<td class="left">命名实体识别</td>
<td class="left">NER</td>
<td class="left">从一个句子中识别人名、地名、机构名等</td>
</tr></tbody>
</table>
</div>
            </article>
</div>
        <div class="site-content">
            <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
                    <div class="entry-meta">
                        <span class="posted-on">
                            Posted on <a href="posts/language-model/" rel="bookmark">February 3, 2017</a>
                        </span>
                    </div>
                    <h1><a href="posts/language-model/">语言模型</a></h1>
                </div>
                <div class="entry-content">
                        <p>
语言模型的定义包含两部分
</p>
<ol class="org-ol">
<li>词汇表 \(V\), 这个语言所有词的集合, 每个词表示为 \(w_i\)
</li>
<li>概率函数 \(P(s)\), 其中 \(s\) 中所有句子组成的集合, 也即为由词汇表 \(V\) 中所有词 \(w_i\) 组成的任意长度的序列.
</li>
</ol>
<p>
语言模型对句子的可能性进行建模。假设语言是由所有可能句子组成的集合,其中句子定义为由任意词语, 以任意顺序, 
以任意长度组成的有序序列。用 \(s\) 表示这样一个句子,则语言模型建模为一个概率分布函数 \(P(s)\), 函数值是这个句子的概率。
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">例子</h2>
<div class="outline-text-2" id="text-1">
<p>
假设一个语言的词汇表只包含三个单词:
</p>
<div class="highlight"><pre><span></span><span class="p">[</span><span class="n">you</span><span class="p">,</span> <span class="n">are</span><span class="p">,</span> <span class="n">ok</span><span class="p">]</span>
</pre></div>

<p>
由这个词汇表所产生的所有的句子如下所示.
</p>

<p>
长度为一的有3个:
</p>
<div class="highlight"><pre><span></span><span class="n">you</span>
<span class="n">are</span>
<span class="n">OK</span>
</pre></div>

<p>
长度为二的有9个:
</p>
<div class="highlight"><pre><span></span><span class="n">you</span> <span class="n">you</span>
<span class="n">you</span> <span class="n">are</span>
<span class="n">you</span> <span class="n">OK</span>
<span class="n">are</span> <span class="n">you</span>
<span class="n">are</span> <span class="n">are</span>
<span class="n">are</span> <span class="n">OK</span>
<span class="n">OK</span> <span class="n">you</span>
<span class="n">OK</span> <span class="n">are</span>
<span class="n">OK</span> <span class="n">OK</span>
</pre></div>

<p>
长度为三的有27个:
</p>
<div class="highlight"><pre><span></span><span class="n">you</span> <span class="n">you</span> <span class="n">you</span>
<span class="n">you</span> <span class="n">you</span> <span class="n">are</span>
<span class="n">you</span> <span class="n">you</span> <span class="n">OK</span>
<span class="n">you</span> <span class="n">are</span> <span class="n">you</span>
<span class="n">you</span> <span class="n">are</span> <span class="n">are</span>
<span class="n">you</span> <span class="n">are</span> <span class="n">OK</span>
<span class="o">...</span>
<span class="n">are</span> <span class="n">you</span> <span class="n">OK</span>
<span class="o">...</span>
<span class="n">OK</span> <span class="n">OK</span> <span class="n">OK</span>
</pre></div>

<p>
长度为四的，有3×3×3×3个. 长度为五的，有3×3×3×3x3个. 这个序列是无穷的。
</p>

<p>
然后我们有一个概率分布函数 \(P(s)\) 来计算每一个句子 \(s\) 的概率, 以下是这个函数的一些可能结果的例子:
</p>
\begin{equation}
P(are\ you\ OK) = 0.008 \\
P(you\ are\ OK) = 0.002\\
P(you\ you) = 0 \\
P(OK) = 0.01 \\
P(you) = 0\\
\end{equation}
<p>
例子中表示句子 \("are\ you\ OK"\) 的概率为 \(0.008\) , 句子 \("you\ you"\) 的概率为 \(0\). 
</p>

<p>
这样的一个函数 \(P(s)\) 就是这个语言的语言模型.
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">语言模型的建立</h2>
<div class="outline-text-2" id="text-2">
<p>
给定一个句子 \(s = w_1w_2w_3...w_n\), 其中 \(w_i\) 是一个词. 语言模型就是要求以下函数
</p>

   \begin{equation}
    P(s)=P(w_1w_2w_3...w_n) \\
  = P(w_1)P(w_2|w_1)P(w_3|w_1w_2)...P(w_n|w_1w_2...w_{n-1})\\
= \prod_i{P(w_i|w_1w_2...w_{i-1})}
   \end{equation}

<p>
其中
</p>
<ul class="org-ul">
<li>\(P(w_1w_2w_3...w_n)\) 为 词序列 \(w_1w_2w_3...w_n\) 的联合概率分布
</li>
<li>\(P(w_1)P(w_2|w_1)P(w_3|w_1w_2)...P(w_n|w_1w_2...w_{n-1})\) 是使用的链式法则后的结果
</li>
</ul>
<p>
这个公式可以理解为一个句子的概率是其所有单词概率的乘积, 一个单词的概率取决于他前面的所有的单词. 如果单词表的数目为5000, 
句子的长度为3，那么有1250亿种可能性, 这个在实际情况下是无法计算的.
</p>

<p>
因此，为了使模型能够实际可计算，需要做出一个假设。语言模型中假设一个词只取决于它前面的一个词，与更之前的所有单词无关,
则上式可以转变为
</p>
\begin{equation}
 P(s)=P(w_1w_2w_3...w_n) = \prod_i{P(w_i|w_{i-1})}
\end{equation}


<p>
这便是语言模型的简化形式: 二元语法模型(bigram model). 相应的也有三元语法模型(trigram model)，
每个词依赖于他前面的两个字。 定义如下:
</p>
\begin{equation}
 P(s)=P(w_1w_2w_3...w_n) = \prod_i{P(w_i|w_{i-1}w_{i-2})}
\end{equation}

<p>
三元语法模型是实际中通常使用的语言模型。
</p>

<p>
通常使用一个语料库来计算每个词的概率。语料库可以由任意文档组成。以二元模型为例，每个词的概率的计算的方法为
</p>
\begin{equation}
 P(w_i|w_{i-1})= \frac{c(w_{i-1}w_i)} {\sum_w{c(w_{i-1}w)}}
\end{equation}

<p>
其中 
</p>
<ul class="org-ul">
<li>\(c(w_{i-1}w_i)\) 为所有以 \(w_{i-1}\) 开头，并且以 \(w_i\) 结束的二元组的数目. 
</li>
<li>\(\sum_w{c(w_{i-1}w)}\) 表示所有以 \(w_{i-1}\) 开头, 并且以任意词结束的二元组的数目. 
</li>
</ul>
<p>
概率就是这两个数目的比值.
</p>
</div>
</div>



<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">参数平滑方法</h2>
<div class="outline-text-2" id="text-3">
<p>
以上计算过程中有一个问题，比如计算以下这个句子的时候，句子的概率将为零。
</p>


<p>
这里的问题是:语料库中不可能包括所有可能出现的词序列, 当某个词的组合在语料库中不存在的时候，便会导致概率为零。
此时需要使用平滑方法来解决这个问题。最简单的一种方法是加法平滑方法.
</p>

<p>
加法平滑方法的基本原理是在统计每一个二元组的数目的时候总是为统计出的数目加个一，如下式所示
</p>
\begin{equation}
 P(w_i|w_{i-1})= \frac{c(w_{i-1}w_i) + 1} {\sum_w{(c(w_{i-1}w) + 1)}} 
\end{equation}


<p>
这样计算后,每个词的概率的计算结果总是大于0. 
</p>

<p>
还有很多种平滑方法，如 <a href="https://en.wikipedia.org/wiki/Good%E2%80%93Turing_frequency_estimation">古德图灵方法</a>，katz平滑方法等。
</p>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">语音识别中应用的例子</h2>
<div class="outline-text-2" id="text-4">
<p>
语音识别中,包含以下两个步骤
</p>
<ol class="org-ol">
<li>根据语音数据, 计算出出几种可能的句子. 因为有同音词的存在, 所以这一步可能有多个结果
</li>
<li>根据语言模型, 计算每个句子的概率，选取概率最大的那个句子作为语音识别的结果
</li>
</ol>
<p>
语言模型在第二步发挥了作用.
</p>
</div>
</div>
                </div>
            </article>
</div>
        <div class="site-content">
            <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
                    <div class="entry-meta">
                        <span class="posted-on">
                            Posted on <a href="posts/gradient-descend/" rel="bookmark">February 1, 2017</a>
                        </span>
                    </div>
                    <h1><a href="posts/gradient-descend/">梯度下降算法</a></h1>
                </div>
                <div class="entry-content">
                        <p>
梯度下降算法是一种用于求解函数最小值的数值计算方法。求解函数的极值一般有两种方法，第一种是解析法, 
即函数的极值可以用公式直接计算出来。如对于1元2次方程，我们可以直接求出这个函数的最大值或者最小值。
但对于更高次的方程或者非线性函数, 大多无法求出解析解，此时需要使用数值方法.
</p>


<p>
对于一元函数来说, 函数的梯度就是其导数. 假设函数为
</p>


\begin{equation}
f(x) = 2x^2-4x+3
\end{equation}

<p>
则函数的梯度函数，也即导数为
</p>

\begin{equation}
Grad(x) = 4x-4
\end{equation}

<p>
梯度下降算法的基本原理如下:
</p>

<p>
对于任意一个自变量 \(x\) 的值 \(x_1\), 我们可以计算此时函数的梯度为 \(Grad(x_1)\), 用当前的 \(x\) 的值 \(x_1\)
减去梯度值的一个比例, 得到一个新的自变量 \(x\) 的值 \(x_2 = x_1 - 0.01*Grad(x_1)\). 则函数在这个新的自变量 \(x\)
的值的地方肯定是小于原来的值的地方, 即
</p>
\begin{equation}
f(x_2) &lt; f(x_1)
\end{equation}
<p>
其中 \(0.01\) 为步长值.
</p>


<p>
比如我们取 \(x_1 = 2\), 此时梯度值为 \(4*2-4=4\), 则 \(x_2 = 2 - 0.01*(4) = 1.96\),
</p>

\begin{equation}
f(x_1) = 2*2^2-4*2+3 = 3\\
f(x_2) = 2*1.96^2-4*1.96+3 = 2.843
\end{equation}

<p>
可见 \(f(x_2) &lt; f(x_1)\)
</p>

<p>
其中
</p>
<ul class="org-ul">
<li>\(x_1=2\) 中的 \(2\) 为自变量的初值. 初值可以随机选择, 如果函数是凸的, 不管初值为何,总能找到相同的极值点
</li>
<li>\(0.01\) 为每次迭代的步长值
</li>
</ul>
<p>
重复以上步骤, 选定初值后,根据以上方法不断变化自变量的值, 随着我们每一次的迭代，自变量的值将慢慢向最优值所对应的 \(x\) 值逼近
(对于这个例子, 最优值对应的 \(x = 1\)). 那么只要迭代的次数足够多，我们总会达到这个最优点，由此便求得函数的最小值.
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">梯度的概念</h2>
<div class="outline-text-2" id="text-1">
<p>
以上提到对于一元函数, 其梯度就是函数的导数,梯度值为一个数值。梯度概念是对导数的扩展, 当函数有多于一个自变量的时候.
只是梯度此时是一个向量,向量的每一维分别是对于每一个自变量求偏导数。
</p>

<p>
以一个二元函数为例
</p>
\begin{equation}
f(x_1, x_2) = (x_1-2)^2 + 3x_2
\end{equation}

<p>
函数的梯度函数为
</p>
\begin{equation}
Grad(x_1) = \frac{\partial f}{\partial x_1} = 2x_1-4\\
Grad(x_2) = \frac{\partial f}{\partial x_2}=3\\
Grad(x_1, x_2) = [Grad(x_1), Grad(x_2)] = [2x_1-4, 3]
\end{equation}


<p>
以上讲到的关于自变量沿梯度反方向变化时, 函数值将减小的规则同样适用于二元及更高元的函数. 梯度下降算法的原理也一样,
不同点为此时更新自变量时,是向量操作.
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">函数的等值线</h2>
<div class="outline-text-2" id="text-2">
<p>
梯度总是垂直于函数的等值线。从等值线中可以更加形象地看出梯度下降的原理. 当自变量沿着梯度的方向变化时, 
函数值将增加, 等值线所对应的值会增加. 因此，当我们将自变量沿着梯度的反方向变化时，函数的值将会减小. 
由此我们可以求出函数的一个极小值, 通过让自变量不断的向梯度的反方向变化.
</p>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">步长值</h2>
<div class="outline-text-2" id="text-3">
<p>
  梯度给出了自变量变化的方向, 而步长值指定了每次变化的幅度. 如果步长值选得过大，则可能会导致在一次更新自变量后,
错过极值点，从而造成震荡, 无法求得函数的极值. 因此我们要保证步长值足够小，避免震荡现象的出现.
</p>
</div>
</div>


<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">收敛准则</h2>
<div class="outline-text-2" id="text-4">
<p>
由于是通过迭代的方式一步一步的改变自变量的值来求函数的极值, 那么怎样判断函数已经达到一个极值了呢? 
此时需要有一个收敛准则, 即判断一次迭代后,函数是否达到极值点. 一般使用的收敛准则为:指定一个精确率, 
当函数值的变化率小于这个精确率时，我们就认为收敛了，此时函数的极值已经被找到.
</p>
</div>
</div>


<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">在机器学习算法中的应用</h2>
<div class="outline-text-2" id="text-5">
<p>
对于一个机器学习算法，如果其目标函数可以表示成连续可微的凸函数，则我们可以用梯度下降算法进行求解其最小值或者最大值.
</p>

<p>
例如在对数几率回归算法中, 可以将目标函数写成一个连续可微的凸函数, 然后用梯度下降算法求函数的最小值, 
从而求得模型的参数。
</p>
</div>
</div>
                </div>
            </article>
</div>
        <div class="site-content">
            <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
                    <div class="entry-meta">
                        <span class="posted-on">
                            Posted on <a href="posts/bag-of-words-and-ngram-model/" rel="bookmark">January 13, 2017</a>
                        </span>
                    </div>
                    <h1><a href="posts/bag-of-words-and-ngram-model/">词袋模型和N-gram模型</a></h1>
                </div>
                <div class="entry-content">
                        <p>
词袋模型(bag of words)是常用的语言模型，将文档看作文档中所有词的集合，而忽略词的顺序。尽管丢失了词的顺序这一属性，
但这个模型仍然能够有效用于一些自然处理任务中，如文本分类。
</p>

<p>
N-gram模型是对词袋模型的扩展，N为一个数字，以N＝2为例，2-gram模型将文档看作文档中所有相邻两个词这些词对的集合，
也忽略这些词对在文档中出现的顺序。词袋模型是当N＝1时的特例。
</p>
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">例子</h2>
<div class="outline-text-2" id="text-1">
<p>
对于如下文档：
</p>
<pre class="example">
The brown fox jump up the rog.
</pre>

<p>
对应的词袋模型为：
</p>
<pre class="example">
(The, brown, fox, jump, up, the, rog)
</pre>

<p>
对应的2-gram模型为：
</p>
<div class="highlight"><pre><span></span>((The, brown), (brown, fox), (fox, jump), (jump, up), (up, the), (the, rog))
</pre></div>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">文档表示</h2>
<div class="outline-text-2" id="text-2">
<p>
将文档表示成词袋模型后,就可以进行定量的分析。一种简单的方式是判断这个文档中是否出现词汇表中某一个词，因此可以将文档表示成一个由0和1组成的向量。
</p>

<p>
如果语言的词汇表如下:
</p>
<pre class="example">
(a, boy, the, cute, likes, dog, little, girl)
</pre>

<p>
则文档与向量表示的对应关系如下.
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="left">
<col class="left">
</colgroup>
<thead><tr>
<th scope="col" class="left">文档</th>
<th scope="col" class="left">向量表示</th>
</tr></thead>
<tbody>
<tr>
<td class="left">a little girl</td>
<td class="left">[1, 0, 0, 0, 0, 0, 1, 1]</td>
</tr>
<tr>
<td class="left">the body likes the dog</td>
<td class="left">[0, 1, 1, 0, 1, 1, 0, 0]</td>
</tr>
</tbody>
</table>
<p>
其中向量中的每个元素表示这个文档中是否包含某个词. 如第一向量, 最后一个 1 表示它包含 girl这个词.
</p>

<p>
进一步的可以考虑词语频率(term frequency, TF)的影响，相当于是在前一个表示的模型新增了词语频率这一信息。
词的频率此时可以作为某种度量的权重.
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="left">
<col class="left">
</colgroup>
<thead><tr>
<th scope="col" class="left">文档</th>
<th scope="col" class="left">向量表示</th>
</tr></thead>
<tbody>
<tr>
<td class="left">a little girl</td>
<td class="left">[1, 0, 0, 0, 0, 0, 1, 1]</td>
</tr>
<tr>
<td class="left">the body likes the dog</td>
<td class="left">[0, 1, 2, 0, 1, 1, 0, 0]</td>
</tr>
</tbody>
</table>
<p>
第二个向量的第三元素值为2,表示 the 在这个文档中出现了两次.
</p>


<p>
有些词出现的频率非常高，可能在每一篇文档中都会出现，因此引入文档频率(doc frequency, DF)，
也即一个词在所有文档中出现的频率。 如果这个频率很高，那么这个词可能是一个停止词， 需要将其移除，
因为它对文档分类没有帮助。
</p>
</div>
</div>


<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">与语言模型的关系</h2>
<div class="outline-text-2" id="text-3">
<p>
词袋模型是语音模型的一种简化形式。语言模型是给定一个词汇表，然后求所有的词的序列的概率。
词袋模型则是将这个词的序列的范围大大缩小，词的序列只包含由单个词所组成的序列，则每个序列的概率则等于词频率。
</p>


<p>
语言模型的详细介绍见<a href="posts/bag-of-words-and-ngram-model/language-model.html">这里</a>.
</p>
</div>
</div>
<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">在信息检索中的应用</h2>
<div class="outline-text-2" id="text-4">
<p>
信息检索要解决的问题是:给定一组关键字, 在所有的文档集合中, 返回与关键字相关的所有文档, 并对所有文档根据相关性进行排序.
</p>

<p>
基本的处理方法为: 首先将所有文档表示为词袋模型,表示为一个向量,然后查询搜索关键字是否包含在这个向量里,
这样便可以计算出所有与给定关键字相关的文档. 排序文档时,可能根据词频-逆文档频率(TF-IDF)进行排序.
</p>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">在文本分类的应用</h2>
<div class="outline-text-2" id="text-5">
<p>
使用词袋模型的向量表示将每个文档表示为数学的形式,然后再输入到具体机器学习算法中.
</p>
</div>
</div>
                </div>
            </article>
</div>
        <div class="site-content">
            <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
                    <div class="entry-meta">
                        <span class="posted-on">
                            Posted on <a href="posts/recall-precision-fscore/" rel="bookmark">January 7, 2017</a>
                        </span>
                    </div>
                    <h1><a href="posts/recall-precision-fscore/">Recall，Precision 和 F-score</a></h1>
                </div>
                <div class="entry-content">
                        <p>
这个三个数据用于描述一个模型的好坏程度，分别为召回率、准确度和F值。
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">定义</h2>
<div class="outline-text-2" id="text-1">
<p>
在二分类模型中，对于任意一个输入数据，结果只用两个：正类或者负类。对于一个输入数据集，假定该模型产生如下结果：
</p>

<ul class="org-ul">
<li>PT： 模型结果为正类且真实为正类的数目
</li>
<li>PF： 模型结果为正类且真实为负类的数目
</li>
<li>NT： 模型结果为负类且真实为负类的数目
</li>
<li>NF： 模型结果为负类且真实为正类的数目
</li>
</ul>
<p>
则召回率、准确度和F值的定义分别为：
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="left">
<col class="left">
</colgroup>
<tbody>
<tr>
<td class="left">Recall</td>
<td class="left">\(\frac{PT}{PT + NF}\)</td>
</tr>
<tr>
<td class="left">Precision</td>
<td class="left">\(\frac{PT}{PT + PF}\)</td>
</tr>
<tr>
<td class="left">F-score</td>
<td class="left">\(\frac{Recall + Precision}{2}\)</td>
</tr>
</tbody>
</table>
<p>
召回率和准确度具有相同的分子，分母不同。F值是二者的算数平均数。
</p>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">搜索引擎的例子</h2>
<div class="outline-text-2" id="text-2">
<p>
假设给定一个关键字， 搜索引擎返回了100个文档，其中80个是正确的，也即符合关键字，
剩余20个是错误的，也即和给定的关键字没有关系。则此时准确度为： \(80/100 = 80\%\)
</p>

<p>
假设还有40篇文档也符合这个关键字，但搜索引擎并没有返回这40篇文档，则召回率为： \(80 / (80 + 40) = 67\%\)
</p>

<p>
由此可见， 召回率表示了搜索引擎从所有符合条件的文档中“召回”正确文档的比例， 而准确度表示了搜索引擎返回文档中正确文档的比例。
所有符合条件的文档和返回文档这两个概念是不同的。
</p>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">进一步思考</h2>
<div class="outline-text-2" id="text-3">
<p>
召回率描述了是否有遗漏，准确度描述了是否正确，F值综合了二者。
</p>

<p>
  如果一个模型如果准确率很高，但召回率很低，即使结果中大多数数据是正确的，但却遗漏了很多正确的数据。如果一个模型召回率很高，
但准确率很低，则表示这个模型可能返回所有正确的数据，但返回的数据中，错误的数据也很多。
</p>

<p>
好的模型应该做到召回率和准确率都较高，也即F值较高。
</p>
</div>
</div>
                </div>
            </article>
</div>
        <div class="site-content">
            <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
                    <div class="entry-meta">
                        <span class="posted-on">
                            Posted on <a href="posts/python-descriptor/" rel="bookmark">March 6, 2016</a>
                        </span>
                    </div>
                    <h1><a href="posts/python-descriptor/">Python描述符简介</a></h1>
                </div>
                <div class="entry-content">
                        <p>
NOTE: 以下为语音笔记，待整理
</p>


<p>
使用描述符控制python对象属性的访问。
</p>

<p>
蟒蛇中定义的所有，数据都可以，称之为，属性。比如函数和变量都是这个类的属性。具体细分一下函数是，非数据属性。而变量是数据属性。描述符用于控制变量的，获取设置和删除。根据属性的不同。描述符也可以进一步细分为数据描述，符合非数据描述符，分别用于控制，数据属性和函数属性。
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">描述符协议</h2>
<div class="outline-text-2" id="text-1">
<p>
任何一个对象只要提包含了get，set delete这三个函数，中的任意一个，那么它就是一个描述符.这三个函数分别控制，属性的获取设置和删除。
</p>
</div>
</div>


<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">第一数据属性以及数据描述符。</h2>
<div class="outline-text-2" id="text-2">
<p>
默认情况下，数据属性的获取顺序为，第一从对象的字典中获取，第二从类字典中获取
。
该如果定义了一个类属性对象，并且这个对象是一个描述符，则获取这个属性是会优先从这个描述符，的各个方法中获取。
</p>
</div>
</div>


<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">第二非数据属性。</h2>
<div class="outline-text-2" id="text-3">
<p>
静态函数，类函数都是通过描述符的方式实现的。在函数定义的时候，函数被保存在类的字典里，以一个普通的函数。函数的调用过程可以分为两个两个步骤。第一个是将函数获取出来，第二个是进行实际的调用。描述符是在第一个步骤中发挥作用。它会将，函数从类的字典中取出来，然后将类对象绑定为，第一个，参数。及成员函数的第一个参数及c f变量，都是在描述符中的钙函数中绑定的。
如果将函数的获取与调用看作两个不同的过程，则已向过则以上过程会，简化。函数本身就是一个描述符，他会返回一个新的函数，这个函数哪和原来的函数一样，但是，第一个参数会被设置为，会被设置为，对象本身。因此心身的函数，将接受的参数比原来的函数，少一个。因为函数本身也是一个描述符。
</p>
</div>
</div>


<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">第三描述符的一些应用。</h2>
</div>


<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">其他的一些。</h2>
<div class="outline-text-2" id="text-5">
<p>
描述服务提供了一个抽象城。这个层次控制性的，访问与设置。
所有函数是一个描述服。
累本身应该不是苗舒服。
</p>
</div>
</div>
                </div>
            </article>
</div>
        <div class="site-content">
            <article class="format-standard libretto-long-form"><div class="title-block post-format-icon-pin">
                    <div class="entry-meta">
                        <span class="posted-on">
                            Posted on <a href="posts/emacs-lisp/" rel="bookmark">September 24, 2015</a>
                        </span>
                    </div>
                    <h1><a href="posts/emacs-lisp/">Emacs Lisp 编程笔记</a></h1>
                </div>
                <div class="entry-content">
                        <div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li>
<a href="posts/emacs-lisp/#sec-1">错误处理</a>
<ul>
<li><a href="posts/emacs-lisp/#sec-1-1">抛出错误</a></li>
<li><a href="posts/emacs-lisp/#sec-1-2">捕获错误</a></li>
<li><a href="posts/emacs-lisp/#sec-1-3">忽略错误</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">错误处理</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1">抛出错误</h3>
<div class="outline-text-3" id="text-1-1">
<div class="highlight"><pre><span></span><span class="p">(</span><span class="nf">signal</span> <span class="ss">'my-error</span> <span class="o">'</span><span class="p">(</span><span class="s">"This is a demo error"</span><span class="p">))</span>
<span class="p">(</span><span class="nf">error</span> <span class="s">"This is another error"</span><span class="p">)</span>
</pre></div>
<p>
What's the difference between the two?
</p>
</div>
</div>

<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2">捕获错误</h3>
<div class="outline-text-3" id="text-1-2">
<div class="highlight"><pre><span></span><span class="p">(</span><span class="nf">progn</span>
  <span class="p">(</span><span class="nf">condition-case</span> <span class="nv">err</span>
      <span class="p">(</span><span class="nf">signal</span> <span class="ss">'my-error</span> <span class="o">'</span><span class="p">(</span><span class="s">"This is a demo error"</span><span class="p">))</span>
    <span class="p">(</span><span class="ss">'my-error</span> <span class="p">(</span><span class="nf">message</span> <span class="s">"my error handled, %s"</span> <span class="nv">err</span><span class="p">)))</span>
  <span class="p">(</span><span class="nf">message</span> <span class="s">"end"</span><span class="p">))</span>

<span class="p">(</span><span class="nf">defun</span> <span class="nv">aaa</span> <span class="p">()</span>
  <span class="p">(</span><span class="nf">interactive</span><span class="p">)</span>
  <span class="p">(</span><span class="nf">condition-case</span> <span class="nv">error</span>
      <span class="p">(</span><span class="nf">progn</span>
	<span class="p">(</span><span class="nf">op/git-change-branch</span> <span class="nv">op/repository-directory</span> <span class="s">"source"</span><span class="p">)</span>
	<span class="p">(</span><span class="nf">op/git-commit-changes</span> <span class="nv">op/repository-directory</span> <span class="s">"Changes"</span><span class="p">))</span>
    <span class="o">'</span><span class="p">(</span><span class="ss">'git-error</span>  <span class="p">(</span><span class="nf">message</span> <span class="s">"Error is %s"</span> <span class="nv">error</span><span class="p">))))</span>

<span class="p">(</span><span class="nf">aaa</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-1-3" class="outline-3">
<h3 id="sec-1-3">忽略错误</h3>
<div class="outline-text-3" id="text-1-3">
<div class="highlight"><pre><span></span><span class="p">(</span><span class="nf">progn</span>
  <span class="p">(</span><span class="nf">ignore-errors</span>
    <span class="c1">;;(signal 'my-error '("This is a demo error"))</span>
    <span class="p">(</span><span class="nf">error</span> <span class="s">"This is another error"</span><span class="p">)</span>
    <span class="p">)</span>
  <span class="p">(</span><span class="nf">message</span> <span class="s">"end"</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
                </div>
            </article>
</div>
    <!-- Lower Navigation links -->
    <nav class="site-content navigation-post" role="navigation"><div class="previous">
                <a href="." rel="prev" onclick="return false;">
                    <span class="meta-nav">No More Older Entries</span>                </a>
            </div>
            <div class="next">
                <a href="." rel="next">
                    <span class="meta-nav">Newer Entries</span>                </a>
            </div>
    </nav><!-- Page Footer --><section class="footer-sidebar clear" role="complementary"><div class="widget-block">
            <aside class="widget"><h2 class="widget-title">Astropeak</h2>
                <div class="widget-text">Astropeak's blogs.</div>
            </aside>
</div>
    </section><!-- Site Attributions --><footer class="site-footer" role="contentinfo"><div class="site-info">
            <p>Contents © 2018         <a href="mailto:astropeak@gmail.com">Astropeak</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </p>
        </div>
        <div class="social">
            <ul class="menu"></ul>
</div>
    </footer>
</body>
</html>
