<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>语言模型 | Astropeak</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://astropeak.github.io/posts/language-model/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Astropeak">
<link rel="prev" href="../gradient-descend/" title="梯度下降算法" type="text/html">
<link rel="next" href="../nlp-vocabulary/" title="自然语言处理名词表" type="text/html">
<meta property="og:site_name" content="Astropeak">
<meta property="og:title" content="语言模型">
<meta property="og:url" content="https://astropeak.github.io/posts/language-model/">
<meta property="og:description" content="语言模型的定义包含两部分


词汇表 \(V\), 这个语言所有词的集合, 每个词表示为 \(w_i\)

概率函数 \(P(s)\), 其中 \(s\) 中所有句子组成的集合, 也即为由词汇表 \(V\) 中所有词 \(w_i\) 组成的任意长度的序列.




语言模型对句子的可能性进行建模。假设语言是由所有可能句子组成的集合,其中句子定义为由任意词语, 以任意顺序, 
以任意长度组成的有序序">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2017-02-03T00:00:00+08:00">
<meta property="article:tag" content="language model">
<meta property="article:tag" content="nlp">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://astropeak.github.io/">

                <span id="blog-title">Astropeak</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>
                </li>
<li>
<a href="../../rss.xml">RSS feed</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.org" id="sourcelink">Source</a>
    </li>

                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">语言模型</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                    Astropeak
            </span></p>
            <p class="dateline"><a href="." rel="bookmark"><time class="published dt-published" datetime="2017-02-03T00:00:00+08:00" itemprop="datePublished" title="2017-02-03">2017-02-03</time></a></p>
            
        <p class="sourceline"><a href="index.org" class="sourcelink">Source</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>
语言模型的定义包含两部分
</p>
<ol class="org-ol">
<li>词汇表 \(V\), 这个语言所有词的集合, 每个词表示为 \(w_i\)
</li>
<li>概率函数 \(P(s)\), 其中 \(s\) 中所有句子组成的集合, 也即为由词汇表 \(V\) 中所有词 \(w_i\) 组成的任意长度的序列.
</li>
</ol>
<p>
语言模型对句子的可能性进行建模。假设语言是由所有可能句子组成的集合,其中句子定义为由任意词语, 以任意顺序, 
以任意长度组成的有序序列。用 \(s\) 表示这样一个句子,则语言模型建模为一个概率分布函数 \(P(s)\), 函数值是这个句子的概率。
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">例子</h2>
<div class="outline-text-2" id="text-1">
<p>
假设一个语言的词汇表只包含三个单词:
</p>
<div class="highlight"><pre><span></span><span class="p">[</span><span class="n">you</span><span class="p">,</span> <span class="n">are</span><span class="p">,</span> <span class="n">ok</span><span class="p">]</span>
</pre></div>

<p>
由这个词汇表所产生的所有的句子如下所示.
</p>

<p>
长度为一的有3个:
</p>
<div class="highlight"><pre><span></span><span class="n">you</span>
<span class="n">are</span>
<span class="n">OK</span>
</pre></div>

<p>
长度为二的有9个:
</p>
<div class="highlight"><pre><span></span><span class="n">you</span> <span class="n">you</span>
<span class="n">you</span> <span class="n">are</span>
<span class="n">you</span> <span class="n">OK</span>
<span class="n">are</span> <span class="n">you</span>
<span class="n">are</span> <span class="n">are</span>
<span class="n">are</span> <span class="n">OK</span>
<span class="n">OK</span> <span class="n">you</span>
<span class="n">OK</span> <span class="n">are</span>
<span class="n">OK</span> <span class="n">OK</span>
</pre></div>

<p>
长度为三的有27个:
</p>
<div class="highlight"><pre><span></span><span class="n">you</span> <span class="n">you</span> <span class="n">you</span>
<span class="n">you</span> <span class="n">you</span> <span class="n">are</span>
<span class="n">you</span> <span class="n">you</span> <span class="n">OK</span>
<span class="n">you</span> <span class="n">are</span> <span class="n">you</span>
<span class="n">you</span> <span class="n">are</span> <span class="n">are</span>
<span class="n">you</span> <span class="n">are</span> <span class="n">OK</span>
<span class="o">...</span>
<span class="n">are</span> <span class="n">you</span> <span class="n">OK</span>
<span class="o">...</span>
<span class="n">OK</span> <span class="n">OK</span> <span class="n">OK</span>
</pre></div>

<p>
长度为四的，有3×3×3×3个. 长度为五的，有3×3×3×3x3个. 这个序列是无穷的。
</p>

<p>
然后我们有一个概率分布函数 \(P(s)\) 来计算每一个句子 \(s\) 的概率, 以下是这个函数的一些可能结果的例子:
</p>
\begin{equation}
P(are\ you\ OK) = 0.008 \\
P(you\ are\ OK) = 0.002\\
P(you\ you) = 0 \\
P(OK) = 0.01 \\
P(you) = 0\\
\end{equation}
<p>
例子中表示句子 \("are\ you\ OK"\) 的概率为 \(0.008\) , 句子 \("you\ you"\) 的概率为 \(0\). 
</p>

<p>
这样的一个函数 \(P(s)\) 就是这个语言的语言模型.
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">语言模型的建立</h2>
<div class="outline-text-2" id="text-2">
<p>
给定一个句子 \(s = w_1w_2w_3...w_n\), 其中 \(w_i\) 是一个词. 语言模型就是要求以下函数
</p>

   \begin{equation}
    P(s)=P(w_1w_2w_3...w_n) \\
  = P(w_1)P(w_2|w_1)P(w_3|w_1w_2)...P(w_n|w_1w_2...w_{n-1})\\
= \prod_i{P(w_i|w_1w_2...w_{i-1})}
   \end{equation}

<p>
其中
</p>
<ul class="org-ul">
<li>\(P(w_1w_2w_3...w_n)\) 为 词序列 \(w_1w_2w_3...w_n\) 的联合概率分布
</li>
<li>\(P(w_1)P(w_2|w_1)P(w_3|w_1w_2)...P(w_n|w_1w_2...w_{n-1})\) 是使用的链式法则后的结果
</li>
</ul>
<p>
这个公式可以理解为一个句子的概率是其所有单词概率的乘积, 一个单词的概率取决于他前面的所有的单词. 如果单词表的数目为5000, 
句子的长度为3，那么有1250亿种可能性, 这个在实际情况下是无法计算的.
</p>

<p>
因此，为了使模型能够实际可计算，需要做出一个假设。语言模型中假设一个词只取决于它前面的一个词，与更之前的所有单词无关,
则上式可以转变为
</p>
\begin{equation}
 P(s)=P(w_1w_2w_3...w_n) = \prod_i{P(w_i|w_{i-1})}
\end{equation}


<p>
这便是语言模型的简化形式: 二元语法模型(bigram model). 相应的也有三元语法模型(trigram model)，
每个词依赖于他前面的两个字。 定义如下:
</p>
\begin{equation}
 P(s)=P(w_1w_2w_3...w_n) = \prod_i{P(w_i|w_{i-1}w_{i-2})}
\end{equation}

<p>
三元语法模型是实际中通常使用的语言模型。
</p>

<p>
通常使用一个语料库来计算每个词的概率。语料库可以由任意文档组成。以二元模型为例，每个词的概率的计算的方法为
</p>
\begin{equation}
 P(w_i|w_{i-1})= \frac{c(w_{i-1}w_i)} {\sum_w{c(w_{i-1}w)}}
\end{equation}

<p>
其中 
</p>
<ul class="org-ul">
<li>\(c(w_{i-1}w_i)\) 为所有以 \(w_{i-1}\) 开头，并且以 \(w_i\) 结束的二元组的数目. 
</li>
<li>\(\sum_w{c(w_{i-1}w)}\) 表示所有以 \(w_{i-1}\) 开头, 并且以任意词结束的二元组的数目. 
</li>
</ul>
<p>
概率就是这两个数目的比值.
</p>
</div>
</div>



<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">参数平滑方法</h2>
<div class="outline-text-2" id="text-3">
<p>
以上计算过程中有一个问题，比如计算以下这个句子的时候，句子的概率将为零。
</p>


<p>
这里的问题是:语料库中不可能包括所有可能出现的词序列, 当某个词的组合在语料库中不存在的时候，便会导致概率为零。
此时需要使用平滑方法来解决这个问题。最简单的一种方法是加法平滑方法.
</p>

<p>
加法平滑方法的基本原理是在统计每一个二元组的数目的时候总是为统计出的数目加个一，如下式所示
</p>
\begin{equation}
 P(w_i|w_{i-1})= \frac{c(w_{i-1}w_i) + 1} {\sum_w{(c(w_{i-1}w) + 1)}} 
\end{equation}


<p>
这样计算后,每个词的概率的计算结果总是大于0. 
</p>

<p>
还有很多种平滑方法，如 <a href="https://en.wikipedia.org/wiki/Good%E2%80%93Turing_frequency_estimation">古德图灵方法</a>，katz平滑方法等。
</p>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">语音识别中应用的例子</h2>
<div class="outline-text-2" id="text-4">
<p>
语音识别中,包含以下两个步骤
</p>
<ol class="org-ol">
<li>根据语音数据, 计算出出几种可能的句子. 因为有同音词的存在, 所以这一步可能有多个结果
</li>
<li>根据语言模型, 计算每个句子的概率，选取概率最大的那个句子作为语音识别的结果
</li>
</ol>
<p>
语言模型在第二步发挥了作用.
</p>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/language-model/" rel="tag">language model</a></li>
            <li><a class="tag p-category" href="../../categories/nlp/" rel="tag">nlp</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../gradient-descend/" rel="prev" title="梯度下降算法">Previous post</a>
            </li>
            <li class="next">
                <a href="../nlp-vocabulary/" rel="next" title="自然语言处理名词表">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2018         <a href="mailto:astropeak@gmail.com">Astropeak</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
